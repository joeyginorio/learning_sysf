% For review submission
%\documentclass[acmsmall,review,anonymous]{acmart}
\documentclass[sigplan,10pt]{acmart}

\settopmatter{printfolios=false,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


% Load any additional packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath,amsthm,amsfonts,wasysym,bussproofs}
\usepackage{csquotes}
\usepackage{booktabs,changepage}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{stfloats}

\usepackage{titlesec,epigraph, listings}
\usepackage{etoolbox}
\usepackage{enumitem}

% Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\lam}{\lambda}

\renewenvironment{proof}
    {\textit{Proof.}}
    {\qed\\}
    
\newtheoremstyle{mytheoremstyle} % name
    {}                    % Space above
    {}                    % Space below
    {\itshape}                   % Body font
    {}                 % Indent amount
    {\bfseries}                  % Theorem head font
    {.}                          % Punctuation after theorem head
    {\newline}                      % Space after theorem head
    {}                           % Theorem head spec (can be left empty, meaning ‘normal’)
\theoremstyle{mytheoremstyle}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}




%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption


\begin{document}

%% Title information
\title{Learning in System F}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Joey Velez-Ginorio}
\affiliation{
  \institution{Massachusetts Institute of Technology}
  \streetaddress{43 Vassar St.}
  \city{Cambridge}
  \state{Massachusetts}
  \postcode{02139}
  \country{U.S.A.}                    %% \country is recommended
}
\email{joeyv@mit.edu}   

%% Author with single affiliation.
\author{Nada Amin}
\affiliation{
  \institution{Harvard University}
  \streetaddress{29 Oxford St.}
  \city{Cambridge}
  \state{Massachusetts}
  \postcode{02138}
  \country{U.S.A.}                    %% \country is recommended
}
\email{namin@seas.harvard.edu}


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
Program synthesis, type inhabitance, inductive programming, and theorem proving. Different names for the same problem: learning programs from data. Sometimes the programs are proofs, sometimes they’re terms. Sometimes data are examples, and sometimes they’re types. Yet the aim is the same. We want to construct a program which satisfies some data. We want to learn a program.

What might a programming language look like, if its programs could also be learned? We give it data, and it learns a program from it. This work shows that System F yields a simple approach for learning from types and examples. Beyond simplicity, System F gives us a guarantee on the soundness and completeness of learning. We learn correct programs, and can learn all observationally distinct programs in System F. Unlike previous works, we don't restrict what examples can be. As a result, we show how to learn arbitrary higher-order programs in System F from types and examples. 

\end{abstract}


%% Keywords
%% comma separated list
\keywords{Program Synthesis, Type Theory, Inductive Programming} 
\maketitle


\section{Introduction}
\subsection{A tricky learning problem}

Imagine we're teaching you a program. Your only data is the type $nat \!\to\! nat$. It takes a natural number, and returns a natural number. Any ideas? Perhaps a program which computes...
$$f(x) = x, \;\;\;\;\;\;f(x) = x + 1,\;\;\;\;\;\; f(x) = x + \cdots$$
The good news is that $f(x) = x + 1$ is correct. The bad news is that the data let you learn a slew of other programs too. It doesn't constrain learning enough if we want to teach $f(x) = x + 1$. As teachers, we can provide better data.

Round 2. Imagine we're teaching you a program. But this time we give you an example of the program's behavior. Your data are the type $nat \!\to\! nat$ and an example $f(1) = 2$. It takes a natural number, and seems to return its successor. Any ideas? Perhaps a program which computes...
$$f(x) = x + 1,\;\;\;\;\;\; f(x) = x + 2 - 1,\;\;\;\;\;\; f(x) = x + \cdots$$
The good news is that $f(x) = x + 1$ is correct. And so are all the other programs, as long as we're agnostic to some details. Types and examples impose useful constraints on learning. It's the data we use when learning in System F \cite{girard1989proofs}.

Existing work can learn successor from similar data \cite{osera2015program, polikarpova2016program}. But suppose $nat$ is a church encoding. For some base type $A$, $nat \coloneqq (A \to A) \to (A \to A)$. Natural numbers are then higher-order functions. They take and return functions. In this setting, existing work can no longer learn successor. 

\subsection{A way forward}

The difficulty is with how to handle functions in the return type. The type $nat \!\to\! nat$ returns a function, a program of type $nat$. To learn correct programs, you need to ensure candidates are the correct type or that they obey examples. Imagine we want to verify that our candidate program $f$ obeys $f(1)=2$. With the church encoding, $f(1)$ is a function, and so is $2$. To check $f(1)=2$ requires that we decide function equality---which is undecidable in a Turing-complete language \cite{sipser2006introduction}. Functions in the return type create this issue. There are two ways out.

\begin{enumerate}
\item Don't allow functions in the return type, keep Turing-completeness.
\item Allow functions in the return type, leave Turing-\\completeness.
\end{enumerate}

Route 1 is the approach of existing work. They don't allow functions in the return type, but keep an expressive Turing-complete language for learning. This can be a productive move, as many interesting programs don't return functions.

Route 2 is the approach we take. We don't impose restrictions on the types or examples we learn from. We instead sacrifice Turing-completeness. We choose a language where function equality is decidable, but still expressive enough to learn interesting programs. Our work shows that this too is a productive move, as many interesting programs return functions. This route leads us to several contributions:
\begin{itemize}
\item Detail how to learn arbitrary higher-order programs in System F. (Section 2 \& 3)
\item Prove the soundness and completeness of learning. (Section 2 \& 3)
\item Implement learning, extending strong theoretical guarantees in practice. (Section 4 \& 5)
\end{itemize}

\begin{figure*}[b]
\vspace{.3cm}
\centering
\setlength{\tabcolsep}{12pt}
\begin{tabular}{l r  l r}
\specialrule{.1em}{0em}{.2em}
\specialrule{.1em}{0em}{1em}
    \Large \textsc{Learning} & 
    &  & \framebox{$\Gamma \vdash \tau \rightsquigarrow e$}\\
    & & \\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$x:\tau \in \Gamma$}
            \RightLabel{\textsc{(L-Var)}}
        \UnaryInfC{$\Gamma \vdash \tau \rightsquigarrow x$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma,\alpha \vdash \tau \rightsquigarrow e$}
            \RightLabel{\textsc{(L-TAbs)}}
        \UnaryInfC{$\Gamma \vdash \forall\alpha.\tau \rightsquigarrow \Lambda \alpha.e$}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma,x{:}\tau_1 \vdash \tau_2 \rightsquigarrow e_2$}
            \RightLabel{\textsc{(L-Abs)}}
        \UnaryInfC{$\Gamma \vdash \tau_1 \to \tau_2 \rightsquigarrow \lam x{:}\tau_1.e_2$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma \vdash \forall\alpha.\tau_1 \rightsquigarrow \hat{e}$}
            \RightLabel{\textsc{(L-TApp)}}
        \UnaryInfC{$\Gamma \vdash [\tau_2/\alpha]\tau_1 \rightsquigarrow \hat{e}\,\lceil\tau_2\rceil$}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma \vdash \tau_1 \to \tau_2 \rightsquigarrow \hat{e}$}
        \AxiomC{$\Gamma \vdash \tau_1 \rightsquigarrow e$}
            \RightLabel{\textsc{(L-App)}}
        \BinaryInfC{$\Gamma \vdash \tau_2 \rightsquigarrow \hat{e}\:e$}
        \DisplayProof
    } \\
    & \\
\specialrule{.1em}{1em}{0em}
\end{tabular}
\caption{Learning from types in System F}
    \label{fig:learning}
\end{figure*}

\section{System F}
We assume you are familiar with System F, the polymorphic lambda calculus. You should know its syntax, typing, and evaluation. If you don't, we co-opt its specification in \cite{pierce2002types}. For a comprehensive introduction we defer the confused or rusty there. Additionally, we provide the specification and relevant theorems in the appendix.

Our focus in this section is to motivate System F: its syntax, typing, and evaluation. And why properties of each are advantageous for learning. Treat this section as an answer to the following question: 
\begin{displayquote}
\textit{Why learn in System F?}
\centering
\end{displayquote}
\subsection{Syntax}

% minimal syntax
% expressive enough to encode the useful things
System F's syntax is simple. There aren't many syntactic forms. Whenever we state, prove, or implement things in System F we often use structural recursion on the syntax. A minimal syntax means we are succint when we state, prove, or implement those things.

While simple, the syntax is still expressive. We can encode many staples of typed functional programming: algebraic data types, inductive types, and more \cite{pierce2002types}. For example, consider this encoding of products:
\begin{align*}
\tau_1 \times \tau_2 \,&\coloneqq\; \forall \alpha.(\tau_1 \to \tau_2 \to \alpha) \to \alpha\\
\langle e_1,e_2 \rangle &\coloneqq\; \Lambda \alpha.\lambda f\!:\!(\tau_1 \to \tau_2 \to \alpha).fe_1e_2 
\end{align*}

\subsection{Typing}
% Typed programs are safe : progress + preservation. Later, we leverage this to ensure the safety of programs we learn.
System F is safe. Its typing ensures both progress and preservation, i.e. that well-typed programs do not get stuck and that they do not change type \cite{pierce2002types}. When we introduce learning, we lift this safety and extend it to programs we learn. Because we use this safety in later proofs, we state the progress and preservation theorems in the appendix.

\subsection{Evaluation}
% strongly normalizing, show example of functions equivalent
System F is strongly normalizing. All its programs terminate. As a result, we can use a simple procedure for deciding equality of programs (including functions). 
\begin{enumerate}
\item Run both programs until they terminate.
\item Check if they share the same normal form, up to alpha-equivalence (renaming of variables).
\item If they do, they are equal. Otherwise, unequal.
\end{enumerate}
For example, this decision procedure renders these programs equal:
$$\lambda x\!:\!\tau.x \;\;=_\beta\;\; (\lambda y\!:\!(\tau\to\tau).y)\lambda z\!:\!\tau.z$$
The decision procedure checks that two programs exist in the transitive reflexive closure of the evaluation relation. This only works because programs always terminate, a property we formally state in the appendix.
% Strong normalization means we can decide function equality through the fdollowwing procedure: evaluate term, compare up to alpha equivalence.

\section{Learning from Types}
% present the augmented relation
% state completeness/soundness result? or prove...

% dont need a figure, but state the normal form syntax like osera does
% then introduce the learning from types.
We present learning as a relation between contexts $\Gamma$, programs $e$, and types $\tau$.
$$\Gamma \vdash \tau \rightsquigarrow e$$
The relation asserts that given a context $\Gamma$ and type $\tau$, you can learn program $e$.

Like typing, we define the relation with a set of inference rules. These rules confer similar benefits to typing. We can prove useful properties of learning, and the rules guide implementation. 

Unlike typing, we only consider programs $e$ in normal form. We discuss later how this pays dividends in the implementation. With reference to the syntax in the appendix, we define System F programs $e$ in normal form:
\begin{align*}
e &\coloneqq\; \hat{e} \;\mid\; \lam x\!:\!\tau.e \;\mid\; \Lambda\alpha.e\\
\hat{e} &\coloneqq\; x \;\mid\; \hat{e}\;e \;\mid\; \hat{e}\,\lceil\tau\rceil
\end{align*}

\subsection{Learning, a relation}
If you squint, you may think that learning in Figure \ref{fig:learning} looks a lot like typing in Figure \ref{fig:typing}. The semblance isn't superficial, but instead reflects an equivalence between learning and typing which we later state. Despite this, the learning relation isn't redundant. It forms the core of an extended learning relation in the next section, where we learn from both types and examples. 

\textsc{(L-Var)} says if $x$ is bound to type $\tau$ in the context $\Gamma$, then you can learn the program $x$ of type $\tau$. 
\vspace{.1cm}
\begin{prooftree}
\def\extraVskip{4pt}
\def\labelSpacing{4pt}
	\AxiomC{$x {:} \tau \in x {:} \tau$}
	\RightLabel{\textsc{(L-Var)}}
	\UnaryInfC{$x{:}\tau \vdash \tau \rightsquigarrow x$}
\end{prooftree}
\vspace{.2cm}

\textsc{(L-Abs)} says if $x$ is bound to type $\tau_1$ in the context and you can learn a program $e_2$ from type $\tau_2$, then you can learn the program $\lam x{:}\tau_1.e_2$ from type $\tau_1 \!\to\! \tau_2$ and $x$ is removed from the context.
\vspace{.1cm}
\begin{prooftree}
\def\extraVskip{4pt}
\def\labelSpacing{4pt}
	\AxiomC{$\Gamma,x{:}\tau_1 \vdash \tau_2 \!\to\! \tau_2 \rightsquigarrow \lam y{:}\tau_2.y$}
	\RightLabel{\textsc{(L-Abs)}}
	\UnaryInfC{$\Gamma \vdash \tau_1 \!\to\! \tau_2 \!\to \!\tau_2 \rightsquigarrow \lam x{:}\tau_1.\lam y{:}\tau_2.y$}
\end{prooftree}
\vspace{.2cm}

\textsc{(L-App)} says that if you can learn a program $\hat{e}$ from type $\tau_1 \!\to\! \tau_2$ and a program $e$ from type $\tau_1$, then you can learn $\hat{e}\:e$ from type $\tau_2$.
\vspace{.1cm}
\begin{prooftree}
\def\extraVskip{4pt}
\def\labelSpacing{4pt}
	\AxiomC{$\Gamma \vdash \tau \!\to\! \tau \rightsquigarrow f$}
	\AxiomC{$\Gamma \vdash \tau \rightsquigarrow x$}
	\RightLabel{\textsc{(L-App)}}
	\BinaryInfC{$\Gamma \vdash \tau \rightsquigarrow f\;x $}
\end{prooftree}
\vspace{.2cm}

\textsc{(L-TAbs)} says that if $\alpha$ is in the context, and you can learn a program $e$ from type $\tau$, then you can learn a program $\Lambda\alpha.e$ from type $\forall\alpha.\tau$ and $\alpha$ is removed from the context.
\vspace{.1cm}
\begin{prooftree}
\def\extraVskip{4pt}
\def\labelSpacing{4pt}
	\AxiomC{$\Gamma,\alpha \vdash \alpha \!\to\! \alpha \rightsquigarrow \lam x{:}\alpha.x$}
	\RightLabel{\textsc{(L-TAbs)}}
	\UnaryInfC{$\Gamma \vdash \forall\alpha.\alpha \!\to\! \alpha \rightsquigarrow \Lambda\alpha.\lam x{:}\alpha.x$}
\end{prooftree}
\vspace{.2cm}

\textsc{(T-TApp)} says that if you can learn a program $\hat{e}$ from type $\forall\alpha.\tau_1$, then you can learn the program $\hat{e}\,\lceil\tau_2\rceil$ from type $[\tau_2/\alpha]\tau_1$.
\vspace{.1cm}
\begin{prooftree}
\def\extraVskip{4pt}
\def\labelSpacing{4pt}
	\AxiomC{$\Gamma \vdash \forall\alpha.\alpha\!\to\!\alpha \rightsquigarrow f$}
	\RightLabel{\textsc{(T-TApp)}}
	\UnaryInfC{$\Gamma \vdash \tau\!\to\!\tau \rightsquigarrow f\lceil \tau\rceil$}
\end{prooftree}
\vspace{.2cm}

\subsection{Metatheory}
Learning is a relation. Hence we can discuss its metatheory. We care most about two properties: soundness and completeness. Soundness ensures we learn correct programs. Completeness ensures we learn all programs. 

We state the relevant theorems in this section. Most of the heavy lifting for proving these properties is done by standard proofs of type systems, like progress and preservation. Learning exploits these properties of type systems to provide similar guarantees.

\begin{lemma}[\textsc{Soundness of Learning}]
If $\,\Gamma \vdash \tau \rightsquigarrow e$ then $\Gamma \vdash e : \tau$
\label{soundness-learning}
\end{lemma}

\begin{lemma}[\textsc{Completeness of Learning}]
If $\,\Gamma \vdash e : \tau$ then $\,\Gamma \vdash \tau \rightsquigarrow e$
\label{completeness-learning}
\end{lemma}

Structural induction on the learning and typing rules proves these two lemmas. And together, they directly prove the equivalence of typing and learning.

\begin{theorem}[\textsc{Equivalence of Typing and Learning}]
If and only if $\,\Gamma \vdash \tau \rightsquigarrow e$ then $\Gamma \vdash e : \tau$
\label{equivalence-learning}
\end{theorem}

Because of the equivalence we can extend strong metatheoretic guarantees to learning from examples, for which learning from types is a key step.

\section{Learning from Examples}
% present the augmented relation
% state completeness/soundness result
To learn from examples, we extend our learning relation to include examples $[\chi]$.
$$\Gamma \vdash \tau \rhd [\chi] \rightsquigarrow e$$
The relation asserts that given a context $\Gamma$, a type $\tau$, and examples $[\chi]$, you can learn program $e$.

Examples are lists of tuples with the inputs and output to a program. For example, $[\langle 1,1\rangle]$ describes a program whose input is $1$ and output is $1$. If we want more than one example, we can add to the list: $[\langle 1, 1\rangle, \langle 2,2 \rangle]$. And with System F, types are also valid inputs. So $[\langle Nat,1,1\rangle, \langle Nat,2,2\rangle]$ describes a polymorphic program instantiated at type $Nat$ whose input is $1$ and output is $1$. In general, an example takes the form
$$ \chi \coloneqq \langle e, \chi\rangle \mid \langle \tau, \chi\rangle \mid \langle e,Nil\rangle$$

Importantly, the syntax doesn't restrict what can be an input or output. Any program $e$ or type $\tau$ can be an input. Likewise, any program $e$ can be an output. We can describe any input-output relationship in the language. Note that we use the following short-hand notation for examples: $\langle\tau,\langle e_1, \langle e_2, Nil\rangle\rangle\rangle \equiv \langle \tau, e_1, e_2\rangle$.

\subsection{Learning, a relation}

Unlike the previous learning relation, Figure \ref{fig:learning-examples} looks a bit foreign. Nevertheless, the intuition is simple. We demonstrate with learning polymorphic identity from examples. Without loss of generality, assume a base type $Nat$ and natural numbers.
$$\cdot \vdash \forall\alpha.\alpha \!\to\! \alpha \rhd [\langle Nat,1,1\rangle] \rightsquigarrow \blacksquare$$

Examples describe possible worlds. $\langle Nat,1,1\rangle$ is a world where $\blacksquare$'s input is $Nat$ and $1$, with an output of $1$. Throughout learning we need a way to keep track of these distinct worlds. So our first step is always to duplicate $\blacksquare$, so that we have one per example. We also introduce empty let bindings to record constraints on variables at later steps. \textsc{(L-Wrld)} in Figure \ref{fig:learning-examples} formalizes this step.
$$\cdot \vdash \alpha.\alpha \!\to\! \alpha \rhd [\langle Nat,1,1\rangle] \rightsquigarrow [\texttt{let}\:(\cdot)\:in\:\blacksquare]$$

Now, our target type is $\alpha.\alpha\!\to\! \alpha$. So we know $\blacksquare$ can bind a variable $\alpha$ to some type. And since we have inputs in $[\langle Nat,1,1\rangle]$, we know what that type is. \textsc{(L-ETAbs)}  in Figure \ref{fig:learning-examples} formalizes this step.
$$\alpha \vdash \alpha\!\to\!\alpha \rhd [\langle1,1\rangle] \rightsquigarrow [\texttt{let}\:(\alpha=Nat)\:in\:\blacksquare]$$

Our target type is now $\alpha\!\to\! \alpha$. So we know $\blacksquare$ can bind a variable $x{:}\alpha$ to some program. And since we have inputs in $[\langle 1,1\rangle]$, we know what that program is. \textsc{(L-EAbs)} in Figure \ref{fig:learning-examples} formalizes this step. 
$$\alpha,x{:}\alpha \vdash \alpha \rhd [\langle1\rangle] \rightsquigarrow [\texttt{let}\:(\alpha=Nat,x{:}\alpha=1)\:in\:\blacksquare]$$

There aren't any inputs left to add bindings to our possible worlds. Therefore, we invoke the relation for learning from types (Figure \ref{fig:learning}) to generate a candidate for $\blacksquare$. Then we check that this candidate evaluates to the correct output in each possible world.
$$\alpha,x{:}\alpha \vdash \alpha \rightsquigarrow x \;\;\;\;\;\texttt{let}\:(\alpha=Nat, x{:}\alpha=1)\:in\:x =_\beta 1$$

With our examples satisfied, we can trivially extract the program $\Lambda\alpha.\lambda x{:}\alpha.x$ from the nested \texttt{let} expression. Note that these expressions are merely a syntactic sugaring of System F programs.
\begin{align*}
\texttt{let}\:(\cdot)\:in\:t &\equiv t\\
\texttt{let}\:(x{:}\tau=s)\:in\:t &\equiv (\lambda x{:}\tau.t)s\\
\texttt{let}\:(\alpha=\tau)\:in\:t &\equiv (\Lambda \alpha.t)\lceil\tau\rceil\\
\texttt{let}\:(x{:}\tau=t_1,bs)\:in\:t_2 &\equiv \texttt{let}\:(x{:}\tau=t_1)\:in\:\texttt{let}\:(bs)\:in\:t_2\\
\text{where } b &\coloneqq \;\cdot\; \mid \;x{:}\tau=e, b \;\mid \;\alpha=\tau, b  
\end{align*}

\begin{figure*}[t]
\vspace{.3cm}
\centering
\setlength{\tabcolsep}{12pt}
\begin{tabular}{l r}
\specialrule{.1em}{0em}{.2em}
\specialrule{.1em}{0em}{1em}
    \Large \textsc{Learning} & 
    \framebox{$\Gamma \vdash \tau \rhd [\chi] \rightsquigarrow e$}\\
    & \\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSp]acing{4pt}
    \def\defaultHypSeparation{\hskip .2in}
        \AxiomC{$\Gamma \vdash \tau \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow [\texttt{let}\:(\cdot)\:\texttt{in}\:e_1,\dots,\texttt{let}\:(\cdot)\:\texttt{in}\:e_n]$}
        \AxiomC{$\bigwedge_{i=1}^n e_i =_\beta e_n$}
        \RightLabel{\textsc{(L-Wrld)}}
        \BinaryInfC{$\Gamma \vdash \tau \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow e$}
        

        \DisplayProof
    } \\\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .2in}
        \AxiomC{$\Gamma \vdash \tau \rightsquigarrow e$}
        \AxiomC{$\bigwedge_{i=1}^{n} (\Gamma \vdash \texttt{let}\:(b_i)\:\texttt{in}\: e : \tau)\;\;\;\;\;\;\;\bigwedge_{i=1}^{n} (\texttt{let}\:(b_i)\:\texttt{in}\: e =_\beta \chi_i) $}
            \RightLabel{\textsc{(L-Base)}}
        \BinaryInfC{$\Gamma \vdash \tau \rhd [\langle\chi_1\rangle,\dots,\langle\chi_n\rangle] \rightsquigarrow [\texttt{let}\:(b_1)\:\texttt{in}\: e,\dots,\texttt{let}\:(b_n)\:\texttt{in}\: e]$}
        

        \DisplayProof
    } \\\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .1in}
        \AxiomC{$\Gamma, x{:}\tau_a \vdash \tau_b \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow [\texttt{let}\:(b_1,x{:}\tau_a=e_1)\:\texttt{in}\: e_1,\dots,\texttt{let}\:(b_n,x{:}\tau_a=e_n)\:\texttt{in}\: e_n]$}
        \RightLabel{\textsc{(L-EAbs)}}
        \UnaryInfC{$\Gamma \vdash\tau_{a} \!\to\! \tau_b \rhd [\langle e_1,\chi_1\rangle,\dots,\langle e_n,\chi_n\rangle] \rightsquigarrow [\texttt{let}\:(b_1)\:\texttt{in}\: \lambda x{:}\tau_a.e_1,\dots,\texttt{let}\:(b_n)\:\texttt{in}\: \lambda x{:}\tau_a.e_n]$}
        \DisplayProof
    } \\\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .1in}
		\AxiomC{$\Gamma, \alpha \vdash \tau_a \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow [\texttt{let}\:(b_1,\alpha=\tau_b)\:\texttt{in}\: e_1,\dots,\texttt{let}\:(b_n,\alpha=\tau_b)\:\texttt{in}\: e_n]$}        
        \RightLabel{\textsc{(L-ETAbs)}}
        \UnaryInfC{$\Gamma \vdash \forall\alpha.\tau_a \rhd [\langle\tau_b,\chi_1\rangle,\dots,\langle\tau_b,\chi_n\rangle] \rightsquigarrow [\texttt{let}\:(b_1)\:\texttt{in}\: \Lambda\alpha.e_1,\dots,\texttt{let}\:(b_n)\:\texttt{in}\: \Lambda\alpha.e_n]$}
        \DisplayProof
    } \\
    & \\
\specialrule{.1em}{1em}{0em}
\end{tabular}
\caption{Learning from examples in System F}
    \label{fig:learning-examples}
\end{figure*}

\subsection{Metatheory}
As before, we care most about two properties: soundness and completeness. Soundness ensures we learn correct programs from examples. Completeness ensures we learn all programs from examples.

We state the relevant theorems in this section. This time, there is no equivalence to typing. As a result, the proofs are more distinct. We omit the proofs here, but they are not controversial. Completeness and soundness proofs for similar relations exist in \cite{osera2015program}.

\begin{lemma}[\textsc{Soundness of Learning}]
If $\,\Gamma \vdash \tau \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow e$ then $\Gamma \vdash e : \tau$
\label{soundness-learning-examples}
\end{lemma}

\begin{lemma}[\textsc{Completeness of Learning}]
If $\,\Gamma \vdash e : \tau$ and there exist some $[\chi_1,\dots,\chi_n]$ which satisfies $e$, then $\,\Gamma \vdash \tau \rhd [\chi_1,\dots,\chi_n] \rightsquigarrow e$.
\label{completeness-learning-examples-b}
\end{lemma}

Learning from examples maintains strong metatheoretic properties. As a result, it forms the basis for a powerful approach towards learning programs from examples. However, the relation is highly non-deterministic, and does not directly translate to an algorithm. Nevertheless, it does provide a blueprint for what that algorithm looks like---as we saw when learning polymorphic identity. In the next sections we explore the strength of this approach by implementing learning in System F.

\newpage
\section{Implementation}


% how to make combinatorial search easier
% - enumerating normal form programs
% - deducing operationally distinct type applications
% - memoizing recurisve calls?
% - algebraic data types let us use examples productively
%    - sum types split examples
%	 - product types generate subproblems

\section{Experiments}


\section{Related Work}


\subsection{Type-driven synthesis}


\section{Conclusion}



%% Acknowledgments
%%\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
%%  This material is based upon work supported by the
%%  \grantsponsor{GS100000001}{National Science
%%    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%%  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%%  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%%  conclusions or recommendations expressed in this material are those
%%  of the author and do not necessarily reflect the views of the
%%  National Science Foundation.
%%\end{acks}

%% Bibliography
\bibliography{refs.bib}

\newpage
%% Appendix
%%\appendix
\section{Appendix}
\subsection{Specification of System F}
\begin{figure*}[b]
\centering
\setlength{\tabcolsep}{12pt}
\begin{tabular}{l  r}
\specialrule{.1em}{0em}{.2em}

\specialrule{.1em}{0em}{1em}
    \Large \textsc{Syntax} & \\
    & \\
    \begin{math}
    \setlength{\jot}{-2pt}
    \begin{aligned}
    e ::= \;& && \hspace*{.25in} \textsc{terms:}\\
        & x && \hspace*{.25in} \textit{variable}\\
        & e_1e_2 && \hspace*{.25in} \textit{application}\\
        & \lam x {:} \tau.e && \hspace*{.25in} \textit{abstraction}\\
        & e\lceil\tau\rceil && \hspace*{.25in} \textit{type application}\\    
        & \Lambda\alpha.e && \hspace*{.25in} \textit{type abstraction}\\
    \\
    v ::= \;& && \hspace*{.25in} \textsc{values:} \\
        & \lam x {:}\tau.e && \hspace*{.25in} \textit{abstraction}\\
        & \Lambda\alpha.e && \hspace*{.25in} \textit{type abstraction}\\
    \end{aligned}
    \end{math} & 
    \begin{math}
    \setlength{\jot}{-2pt}
    \begin{aligned}
    \tau ::= \;& && \hspace*{.25in} \textsc{types:}\\
        & \tau_1 \to \tau_2 && \hspace*{.25in} \textit{function type}\\
        & \forall\alpha.\tau && \hspace*{.25in} \textit{polymorphic type}\\
        & \alpha && \hspace*{.25in} \textit{type variable}\\
    \\
    \Gamma ::= \;& && \hspace*{.25in} \textsc{contexts:}\\
        & \cdot && \hspace*{.25in} \textit{empty}\\
        & x{:}\tau,\Gamma && \hspace*{.25in} \textit{variable}\\
        & \alpha,\Gamma && \hspace*{.25in} \textit{type variable}
    \end{aligned}
    \end{math}\\
    &\\
\specialrule{.1em}{1em}{0em}
\end{tabular}
\caption{Syntax in System F}
    \label{fig:syntax}
\end{figure*}

\begin{figure*}[b]
\centering
\setlength{\tabcolsep}{12pt}
\begin{tabular}{l r  l r}
\specialrule{.1em}{0em}{.2em}
\specialrule{.1em}{0em}{1em}
    \Large \textsc{Typing} & 
    &  & \framebox{$\Gamma \vdash e : \tau$}\\
    & & \\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$x:\tau \in \Gamma$}
            \RightLabel{\textsc{(T-Var)}}
        \UnaryInfC{$\Gamma \vdash x : \tau$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma,\alpha \vdash e : \tau$}
            \RightLabel{\textsc{(T-TAbs)}}
        \UnaryInfC{$\Gamma \vdash \Lambda \alpha.e:\forall\alpha.\tau$}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma,x{:}\tau_1 \vdash e_2 : \tau_2$}
            \RightLabel{\textsc{(T-Abs)}}
        \UnaryInfC{$\Gamma \vdash \lam x{:}\tau_1.e_2:\tau_1 \to \tau_2$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma \vdash e : \forall\alpha.\tau_1$}
            \RightLabel{\textsc{(T-TApp)}}
        \UnaryInfC{$\Gamma \vdash e\lceil\tau_2\rceil : [\tau_2/\alpha]\tau_1$}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$\Gamma \vdash e_1 : \tau_1 \to \tau_2$}
        \AxiomC{$\Gamma \vdash e_2 : \tau_1$}
            \RightLabel{\textsc{(T-App)}}
        \BinaryInfC{$\Gamma \vdash e_1e_2 : \tau_2$}
        \DisplayProof
    } \\
    & \\
\specialrule{.1em}{1em}{0em}
\end{tabular}
\caption{Typing in System F}
    \label{fig:typing}
\end{figure*}

\begin{theorem}[\textsc{Progress in Typing}]
If $e$ is a closed, well-typed program, then either $e$ is a value or else there is some program $e'$ such that $e \to_\beta e'$.
\label{progress-typing}
\end{theorem}
\begin{theorem}[\textsc{Preservation in Typing}]
If $\,\Gamma \vdash e : \tau$ and $e \to_\beta e'$, then $\Gamma \vdash e' : \tau$.
\label{preservation-typing}
\end{theorem} 

\begin{figure*}[b]
\centering
\setlength{\tabcolsep}{12pt}
\begin{tabular}{l r  l r}
\specialrule{.1em}{0em}{.2em}
\specialrule{.1em}{0em}{1em}
    \Large \textsc{Evaluating} & 
    &  & \fbox{ $e \to_\beta e'$}\\
    & & \\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$e_1 \to_\beta e_1'$}
            \RightLabel{\textsc{(E-App1)}}
        \UnaryInfC{$e_1e_2 \to_\beta e_1'e_2$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$e \to_\beta e'$}
            \RightLabel{\textsc{(E-TApp)}}
        \UnaryInfC{$e\lceil\tau\rceil \to_\beta e'\lceil\tau\rceil$}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$e_2 \to_\beta e_2'$}
            \RightLabel{\textsc{(E-App2)}}
        \UnaryInfC{$e_1e_2 \to_\beta e_1e_2'$}
        \DisplayProof
    } &
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$(\Lambda\alpha.\lam x{:}\alpha.e)\lceil\tau\rceil \to_\beta (\lam x{:}\alpha.e)[\tau/\alpha]\,\,$\textsc{(E-TSub)}}
        \DisplayProof
    }
    \\
    & &\\
    \multicolumn{2}{c}{
    \def\extraVskip{4pt}
    \def\labelSpacing{4pt}
    \def\defaultHypSeparation{\hskip .05in}
        \AxiomC{$(\lam x{:}\tau.e)v \to_\beta e[v/x]\,\,$\textsc{(E-Sub)}}
        \DisplayProof
    } \\
    & \\
\specialrule{.1em}{1em}{0em}
\end{tabular}
\caption{Evaluating in System F}
    \label{fig:evaluating}
\end{figure*}

\begin{theorem}[\textsc{Normalization in Evaluation}]
Well-typed programs in System F always evaluate to a value, to a normal form.
\label{normalization-evaluation}
\end{theorem}
%%Text of appendix \ldots

\end{document}
